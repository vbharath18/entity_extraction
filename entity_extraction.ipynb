{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "\n",
    "import os\n",
    "import logging\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from typing_extensions import List, Optional\n",
    "from datetime import date\n",
    "import gradio as gr\n",
    "from pydantic import BaseModel, Field, ValidationInfo, field_validator\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Environment Variables and Initialize Azure OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Load the OCR data\n",
    "\n",
    "ocr_file_path = \"./data/microsoft_ocr.md\"\n",
    "faiss_index_path = \"./data/faiss_index\"\n",
    "\n",
    "# Check required environment variables\n",
    "\n",
    "azure_openai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_deployment_name = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "\n",
    "if not azure_openai_api_key:\n",
    "    raise ValueError(\"AZURE_OPENAI_API_KEY environment variable not set\")\n",
    "if not azure_endpoint:\n",
    "    raise ValueError(\"AZURE_OPENAI_ENDPOINT environment variable not set\")\n",
    "\n",
    "# Initialize Azure OpenAI client\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_key=azure_openai_api_key,\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    deployment_name=azure_deployment_name,  \n",
    "    logprobs=True, # Set to True to get logprobs\n",
    "    top_logprobs=1 # Set to 1 to get the top logprobs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Helper Functions for semantic search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_markdown_for_embeddings():\n",
    "    \"\"\"Process Markdown file for embedding using langchain components\"\"\"\n",
    "    \n",
    "    try:\n",
    "        with open(ocr_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            full_text = f.read()\n",
    "        \n",
    "        # Create text splitter\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=100,\n",
    "            chunk_overlap=50,\n",
    "            length_function=len,\n",
    "            is_separator_regex=False,\n",
    "        )\n",
    "        \n",
    "        # Split text into chunks\n",
    "        texts = text_splitter.create_documents([full_text])\n",
    "        return texts\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing Markdown for embedding: {e}\")\n",
    "        return None\n",
    "\n",
    "def setup_rag(document_splits=None):\n",
    "    \"\"\"Initialize RAG components with document embedding using FAISS\"\"\"\n",
    "    global vector_store  # Add this line to modify the global variable\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    azure_openai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "    \n",
    "    # Initialize embeddings\n",
    "    embeddings = AzureOpenAIEmbeddings(\n",
    "        azure_deployment=\"text-embedding-ada-002\",\n",
    "        openai_api_version=\"2023-05-15\",\n",
    "        azure_endpoint=azure_endpoint,\n",
    "        api_key=azure_openai_api_key,\n",
    "    )\n",
    "    \n",
    "    # Initialize or load FAISS vector store\n",
    "    if document_splits:\n",
    "        vector_store = FAISS.from_documents(document_splits, embeddings)\n",
    "        # Optionally save the index\n",
    "        vector_store.save_local(faiss_index_path)\n",
    "    else:\n",
    "        # Load existing index if available\n",
    "        try:\n",
    "            vector_store = FAISS.load_local(faiss_index_path, embeddings)\n",
    "        except:\n",
    "            # Return None or handle the case when no index exists\n",
    "            return None\n",
    "    return vector_store\n",
    "\n",
    "def is_vector_store_initialized():\n",
    "    \"\"\"Check if the vector store is initialized.\"\"\"\n",
    "    return vector_store is not None\n",
    "\n",
    "def semantic_search(query, k, filter=None):\n",
    "    \"\"\"Perform semantic search from the vector store to retrieve relevant chunks\"\"\"\n",
    "    if not is_vector_store_initialized():\n",
    "        logging.error(\"Vector store is not initialized.\")\n",
    "        return None\n",
    "    \n",
    "    results = vector_store.similarity_search(query, k=k, filter=filter)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Markdown for Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='<figure>\\n</figure>\\n\\n\\nMC-2202\\n\\n\\n<figure>\\n\\nsterling\\nACCURIS\\nPathology lab that cares\\n\\n</figure>'),\n",
       " Document(metadata={}, page_content='</figure>\\n\\n\\nScan QR code to check\\nreport authenticity\\n\\nPassport No :\\n\\n\\n# LABORATORY TEST REPORT'),\n",
       " Document(metadata={}, page_content='<table>\\n<tr>\\n<th>Patient Information</th>\\n<th colspan=\"2\">Sample Information</th>'),\n",
       " Document(metadata={}, page_content='<th colspan=\"2\">Sample Information</th>\\n<th>Client/Location Information</th>\\n</tr>\\n<tr>'),\n",
       " Document(metadata={}, page_content='<td rowspan=\"2\">Name : Lyubochka Svetka Sex/Age Male / 41 Y 01-Feb-1982 Ref. Id : Ref. By :</td>')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_splits = process_markdown_for_embeddings()\n",
    "\n",
    "# Display the first few document splits to verify\n",
    "document_splits[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup RAG (Retrieval-Augmented Generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG setup successful.\n"
     ]
    }
   ],
   "source": [
    "# Initialize RAG components with document embedding using FAISS\n",
    "rag_chain = setup_rag(document_splits)\n",
    "\n",
    "# Check if the RAG setup was successful\n",
    "if rag_chain:\n",
    "    print(\"RAG setup successful.\")\n",
    "else:\n",
    "    print(\"RAG setup failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Vector Store Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the vector store is initialized\n",
    "is_initialized = is_vector_store_initialized()\n",
    "\n",
    "# Display the initialization status\n",
    "is_initialized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='73682d48-22ee-48c2-9f21-fd60ee20e0bd', metadata={}, page_content='Interpretation:'),\n",
       " Document(id='62330667-69f3-418b-8d8e-dbfa723ac7a7', metadata={}, page_content='formed.'),\n",
       " Document(id='bfd854bd-bdbe-4c5e-bff8-efe9999237ac', metadata={}, page_content='1\\\\.'),\n",
       " Document(id='504b319a-d51d-4b46-b27f-cd0829a12fea', metadata={}, page_content='2\\\\.'),\n",
       " Document(id='a496b57d-3128-441b-934d-5835163a654e', metadata={}, page_content='2\\\\.')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the query and perform semantic search\n",
    "query = \"Some word\"\n",
    "results = semantic_search(query, k=5)\n",
    "\n",
    "# Display the search results\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Demographics Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "class Demographics(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "\n",
    "    patient_first_name: Optional[str] = Field(\n",
    "        default=None, description=\"First Name of the patient\"\n",
    "    )\n",
    "   \n",
    "    patient_last_name: Optional[str] = Field(\n",
    "    default=None, description=\"Last Name of the patient\"\n",
    "    )\n",
    "\n",
    "    @field_validator('patient_first_name', 'patient_last_name', mode='after')  \n",
    "    @classmethod\n",
    "    def validate_name(cls, value: str, info: ValidationInfo) -> str:\n",
    "        if not value:\n",
    "            return value\n",
    "        try:\n",
    "            if not is_vector_store_initialized():\n",
    "                return value  # Skip validation if vector store isn't ready\n",
    "            answer = semantic_search(value, k=1)\n",
    "            \n",
    "            display(HTML(pd.DataFrame({\"Value\": [value], \"Grounding\": [answer]}).to_html(index=False, classes='table table-striped table-bordered')))\n",
    "\n",
    "            if not any(value in result.page_content for result in answer):\n",
    "                print(f\"Warning: Could not verify {value} in the knowledge base\")\n",
    "            return value\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Validation error for {value}: {str(e)}\")\n",
    "            return value\n",
    "\n",
    "    patient_dob: Optional[date] = Field(\n",
    "        default=None, description=\"Date of birth of the patient in YYYY-MM-DD format\"\n",
    "    )\n",
    "    patient_phone: Optional[str] = Field(\n",
    "        default=None, description=\"Phone number of the patient\"\n",
    "    )\n",
    "    patient_address: Optional[str] = Field(\n",
    "        default=None, description=\"Address of the patient\"\n",
    "    )\n",
    "    patient_sex: Optional[str] = Field(\n",
    "        default=None, description=\"Sex of the patient\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Data Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(BaseModel):\n",
    "    \"\"\"Extracted data about patient\"\"\"\n",
    "\n",
    "    # Creates a model so that we can extract multiple entities.\n",
    "    people: List[Demographics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Text for Entity Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize structured LLM with the defined schema\n",
    "structured_llm = llm.with_structured_output(schema=Data)\n",
    "\n",
    "def process_text(text_input):\n",
    "    try:\n",
    "        # Create a prompt template\n",
    "        prompt_template = PromptTemplate(input_variables=[\"text\"], template=\"{text}\")\n",
    "        prompt = prompt_template.invoke({\"text\": text_input})\n",
    "        \n",
    "        # Invoke the structured LLM with the prompt\n",
    "        result = structured_llm.invoke(prompt)\n",
    "        \n",
    "        # Check if any people data was extracted\n",
    "        if not result.people:\n",
    "            return \"No data was extracted from the text\"\n",
    "        \n",
    "        # Create lists with consistent lengths\n",
    "        data_lists = []\n",
    "        for person in result.people:\n",
    "            person_data = {\n",
    "                \"First Name\": person.patient_first_name or \"\",\n",
    "                \"Last Name\": person.patient_last_name or \"\",\n",
    "                \"Date of Birth\": person.patient_dob or None,\n",
    "                \"Phone\": person.patient_phone or \"\",\n",
    "                \"Address\": person.patient_address or \"\",\n",
    "                \"Sex\": person.patient_sex or \"\"\n",
    "            }\n",
    "            data_lists.append(person_data)\n",
    "        \n",
    "        # Check if any valid data was extracted\n",
    "        if not data_lists:\n",
    "            return \"No valid data extracted\"\n",
    "        \n",
    "        # Create a DataFrame from the extracted data\n",
    "        df = pd.DataFrame(data_lists)\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        # Print error message for debugging\n",
    "        print(f\"Error during processing: {str(e)}\")\n",
    "        return f\"Error processing the text: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DataFrame Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe table table-striped table-bordered\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Value</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Lyubochka</td>\n",
       "      <td>[page_content='&lt;td rowspan=\"3\"&gt;Name : Lyubochka Svetka Sex/Age : Male / 41 Y 01-Feb-1982 Ref. Id : Ref. By :&lt;/td&gt;']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe table table-striped table-bordered\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Value</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Svetka</td>\n",
       "      <td>[page_content='&lt;td rowspan=\"3\"&gt;Name : Lyubochka Svetka Sex/Age : Male / 41 Y 01-Feb-1982 Ref. Id : Ref. By :&lt;/td&gt;']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe table table-striped table-bordered\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Date of Birth</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Address</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Lyubochka</td>\n",
       "      <td>Svetka</td>\n",
       "      <td>1982-02-01</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# Set default text and OCR file path\n",
    "default_text = \"Please input text to extract demographics.\"\n",
    "\n",
    "# Try to read the OCR file and set the default text\n",
    "try:\n",
    "    if os.path.exists(ocr_file_path):\n",
    "        with open(ocr_file_path, 'r', encoding='utf-8') as file:\n",
    "            default_text = file.read()\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not read OCR file: {str(e)}\")\n",
    "\n",
    "# Process the default text to extract demographics\n",
    "df = process_text(default_text)\n",
    "\n",
    "# Display the DataFrame in a professional format\n",
    "if isinstance(df, pd.DataFrame):\n",
    "    display(HTML(df.to_html(index=False, classes='table table-striped table-bordered')))\n",
    "else:\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
